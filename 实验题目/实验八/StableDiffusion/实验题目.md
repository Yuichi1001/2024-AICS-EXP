# 实验目的

熟悉潜在扩散模型的算法原理，能够在DLP平台上使用Python语言基于Stable Diffusion实现图生图、文生图以及图像修复功能，学会使用Triton语言进行Flash Attention算子的封装并对Stale Diffusion模型进行算子优化，具体包括：

1. 理解基于潜在扩散模型的Stable Diffusion的基本原理关键概念及底层逻辑，及其在图像领域生成中的应用；
2. 掌握Triton语言的基本用法、应用场景和特点；
3. 了解Flash Attention算法的基本原理、算法流程和改进思路；
4. 掌握Stable Diffusion图像生成的基本流程，能够在DLP平台上实现图生图、文生图、图像修复等功能；
5. 学习使用Flash Attention对Stable Diffusion算子进行优化的具体操作步骤。

实验工作量：约300行代码，24小时。



# 实验环境

硬件平台：DLP云平台环境。

软件环境：编程框架Pytorch1.6.0、CNNL高性能AI运算库，CNRT 运行时库，以及 python 环境及相关的扩展库。

   

# 实验内容和步骤

详情请查看实验指导书



# 评分标准

- 60分标准：能够正确实现Stable Diffusion模型的图像生成图像模块。
- 70分标准：在60分的基础上，能够正确实现Stable Diffusion模型的文字生成图像模块。
- 80分标准：在70分的基础上，能够正确实现Stable Diffusion模型的图像修复模块。
- 90分标准：在80分的基础上，能够正确实现基于寒武纪Triton的Flash Attention算子封装，并能够正确实现单算子测试。
- 100分标准：在90分的基础上，能够正确完成Stable Diffusion模型上的算子替换，使用Flash Attention算子正确实现Stable Diffusion的基本功能。


# 文件提交格式

需要提交的文件为stable_diffusion/ldm/models/diffusion/ddim.py、stable_diffusion/scripts/img2img.py、stable_diffusion/scripts/txt2img.py、stable_diffusion/scripts/gradio/inpainting.py、stable_diffusion/flash_attention_triton_opt.py以及stable\_diffusion/ldm/modules/attention.py文件，将上述文件直接打包为 zip 文件提交。