// file: 06_vector_sram_blocks_pipe5.mlu

#include <bang.h>
#include <stdio.h>
#include <stdlib.h>
#include <sys/time.h>

#define DEBUG 0

#define STAGES 2
#define LOOPS 32
#define BLOCKS 128
#define M_PER_LOOP 64
#define M_PER_LOOP_BLOCK (M_PER_LOOP * STAGES)
#define M_PER_LOOP_UNION (M_PER_LOOP_BLOCK * /*coreDim=*/4)
#define M_PER_BLOCK (M_PER_LOOP_BLOCK * LOOPS)

#define M (M_PER_BLOCK * BLOCKS)
#define N 256
#define K 128

float relativeError(float a, float b) {
  float abs_diff = fabs(a - b);
  float max_value = fmax(fabs(a), fabs(b));
  float result = abs_diff / max_value;
  return result;
}

float generateRandomFloat(float min, float max) {
#if DEBUG
  return 1.1;
#else
  float scale = rand() / (float)RAND_MAX;
  return min + scale * (max - min);
#endif
}

__attribute__((noinline)) void multiplyMatricesCPU(float *left, float *right,
                                                   float *result, int m, int n,
                                                   int k) {
  for (int i = 0; i < m; i++) {
    for (int j = 0; j < k; j++) {
      result[i * k + j] = 0.0f;
      for (int x = 0; x < n; x++) {
        // TODO: 请补充标量矩阵乘计算部分代码
        result[i * k + j] += left[i * n + x] * right[x * k + j];
      }
    }
  }
}

__mlu_func__ void multiplyMatrices(float *left, float *right_wram,
                                   float *result, int m, int n, int k) {
  // TODO: 请补充左矩阵NRAM数组的声明
  __nram__ float left_nram[M_PER_LOOP * N * STAGES];
  // TODO: 请补充结果矩阵NRAM数组的声明
  __nram__ float result_nram[M_PER_LOOP * K * STAGES];
  int m_per_block = m / coreDim;
  int m_per_loop = m_per_block / STAGES;
  int loops = STAGES;
  for (int loop = 0; loop < (loops + STAGES); loop++) {
    __sync_io();
    if (loop < loops) {
      // TODO: 请补充将左矩阵从SRAM异步拷贝至NRAM的代码
      __memcpy_async(&left_nram[m_per_loop * N * (loop % STAGES)],
                     &left[m_per_block * (taskId % coreDim) * N + loop * m_per_loop * N],
                     m_per_loop * n * sizeof(float), SRAM2NRAM);
    }
    if (loop >= 1 && loop <= loops) {
      __bang_matmul(result_nram + m_per_loop * k * ((loop - 1) % STAGES),
                    left_nram + m_per_loop * n * ((loop - 1) % STAGES),
                    right_wram, m_per_loop, n, k);
    }
    if (loop >= STAGES) {
      // TODO: 请补充将结果矩阵从NRAM写回SRAM的代码
      __memcpy_async(
          &result[m_per_block * (taskId % coreDim) * K + (loop - STAGES) * m_per_loop * K],
          &result_nram[m_per_loop * k * ((loop - STAGES) % STAGES)],
          m_per_loop * k * sizeof(float), NRAM2SRAM);
    }
    __sync_move();
  }
}

__mlu_entry__ void multiplyMatricesMLU(float *left, float *right, float *result,
                                       int m, int n, int k) {
  // TODO: 请补充左矩阵SRAM数组的声明
  __mlu_shared__ float left_sram[M_PER_LOOP_UNION * N * STAGES];
  __mlu_shared__ float right_sram[N * K];
  __wram__ float right_wram[N * K];
  // TODO: 请补充结果矩阵SRAM数组的声明
  __mlu_shared__ float result_sram[M_PER_LOOP_UNION * K * STAGES];
  int m_per_block = m / taskDim;
  int m_per_union = m_per_block * coreDim;
  int m_per_loop_union = m_per_union / LOOPS;
  // TODO: 请补充将右矩阵从GDRAM异步拷贝至SRAM的代码
  __memcpy_async(right_sram, right, N * K * sizeof(float), GDRAM2SRAM);
  // TODO: 请补充将右矩阵从SRAM异步拷贝至NRAM的代码
  __memcpy_async(right_sram, right, N * K * sizeof(float), GDRAM2SRAM);
  for (int loop = 0; loop < (LOOPS + STAGES); loop++) {
    if (loop < LOOPS) {
      // TODO: 请补充将左矩阵从GDRAM异步拷贝至SRAM的代码
      __memcpy_async(&left_sram[m_per_loop_union * N * (loop % STAGES)],
                     &left[(taskId * m_per_block + loop * m_per_loop_union) * N],
                     m_per_loop_union * n * sizeof(float), GDRAM2SRAM);
    }
    if (loop >= 1 && loop <= LOOPS) {
      multiplyMatrices(
          left_sram + m_per_loop_union * n * ((loop - 1) % STAGES), right_wram,
          result_sram + m_per_loop_union * k * ((loop - 1) % STAGES),
          m_per_loop_union, n, k);
    }
    if (loop >= STAGES) {
      // TODO: 请补充将结果矩阵从SRAM写回GDRAM的代码
      __memcpy_async(
          &result[(taskId * m_per_block + (loop - STAGES) * m_per_loop_union) * k],
          &result_sram[m_per_loop_union * k * ((loop - STAGES) % STAGES)],
          m_per_loop_union * k * sizeof(float), SRAM2GDRAM);
    }
    __sync_cluster();
  }
}

int main() {
  int m = M, n = N, k = K;
  printf("\nM = %d, N = %d, K = %d\n", m, n, k);

  float *left = (float *)malloc(m * n * sizeof(float));
  float *right = (float *)malloc(n * k * sizeof(float));
  float *result = (float *)malloc(m * k * sizeof(float));

  float *left_mlu = NULL, *right_mlu = NULL, *result_mlu = NULL;
  CNRT_CHECK(cnrtMalloc((void **)&left_mlu, m * n * sizeof(float)));
  CNRT_CHECK(cnrtMalloc((void **)&right_mlu, n * k * sizeof(float)));
  CNRT_CHECK(cnrtMalloc((void **)&result_mlu, m * k * sizeof(float)));

  for (int i = 0; i < m; i++) {
    for (int j = 0; j < n; j++) {
      left[i * n + j] = generateRandomFloat(1.0f, 1.1f);
    }
  }

  for (int i = 0; i < n; i++) {
    for (int j = 0; j < k; j++) {
      right[i * k + j] = generateRandomFloat(1.0f, 1.1f);
    }
  }

  CNRT_CHECK(
      cnrtMemcpy(left_mlu, left, m * n * sizeof(float), cnrtMemcpyHostToDev));
  CNRT_CHECK(
      cnrtMemcpy(right_mlu, right, n * k * sizeof(float), cnrtMemcpyHostToDev));

  struct timeval st_cpu, et_cpu;
  gettimeofday(&st_cpu, NULL);
  multiplyMatricesCPU(left, right, result, m, n, k);
  gettimeofday(&et_cpu, NULL);

  float cpu_time_used = (et_cpu.tv_sec - st_cpu.tv_sec) * 1e3 +
                        (et_cpu.tv_usec - st_cpu.tv_usec) / 1e3;
  printf("\nCPU Time taken: %.3f ms\n", cpu_time_used);
#if DEBUG
  printf("\nCPU Result Matrix:\n");
  for (int i = 0; i < m; i++) {
    for (int j = 0; j < k; j++) {
      printf("%f\t", result[i * k + j]);
    }
    printf("\n");
  }
#endif

  cnrtNotifier_t st_mlu, et_mlu;
  CNRT_CHECK(cnrtNotifierCreate(&st_mlu));
  CNRT_CHECK(cnrtNotifierCreate(&et_mlu));
  cnrtQueue_t queue;
  CNRT_CHECK(cnrtQueueCreate(&queue));
  // TODO: 请补充核函数并行规模
  cnrtDim3_t dim = {CNRT_FUNC_TYPE_UNION1, 256, 1};
  cnrtFunctionType_t func_type = CNRT_FUNC_TYPE_UNION1;
  // TODO: 请补充核函数开始计时代码
  CNRT_CHECK(cnrtPlaceNotifier(st_mlu, queue));
  multiplyMatricesMLU<<<dim, func_type, queue>>>(left_mlu, right_mlu,
                                                 result_mlu, m, n, k);
  // TODO: 请补充核函数结束计时代码
  CNRT_CHECK(cnrtPlaceNotifier(et_mlu, queue));
  CNRT_CHECK(cnrtQueueSync(queue));

  float mlu_time_used = 0.0f;
  // TODO: 请补充核函数耗时统计代码
  CNRT_CHECK(cnrtNotifierDuration( st_mlu, et_mlu, &mlu_time_used));
  printf("\nMLU Time taken: %.3f ms\n", mlu_time_used);

  float *result_actual = (float *)malloc(m * k * sizeof(float));
  CNRT_CHECK(cnrtMemcpy(result_actual, result_mlu, m * k * sizeof(float),
                        cnrtMemcpyDevToHost));
#if DEBUG
  printf("\nMLU Result Matrix:\n");
  for (int i = 0; i < m; i++) {
    for (int j = 0; j < k; j++) {
      printf("%f\t", result_actual[i * k + j]);
    }
    printf("\n");
  }
#endif

  bool is_passed = true;
  for (int i = 0; i < m; i++) {
    for (int j = 0; j < k; j++) {
      float diff_rel =
          relativeError(result[i * k + j], result_actual[i * k + j]);
      if (diff_rel > 0.1) {
        printf("diff_rel = %.3f\n", diff_rel);
        printf("[%d, %d]: cpu = %f, mlu = %f\n", i, j, result[i * k + j],
               result_actual[i * k + j]);
        is_passed = false;
      }
    }
  }
  printf(is_passed ? "\n06PASSED\n" : "\n06FAILED\n");

  free(left);
  CNRT_CHECK(cnrtFree(left_mlu));
  free(right);
  CNRT_CHECK(cnrtFree(right_mlu));
  free(result);
  free(result_actual);
  CNRT_CHECK(cnrtFree(result_mlu));
  CNRT_CHECK(cnrtNotifierDestroy(st_mlu));
  CNRT_CHECK(cnrtNotifierDestroy(et_mlu));
  CNRT_CHECK(cnrtQueueDestroy(queue));

  return 0;
}
